from signalfx.detectors.autodetect import utils
from signalfx.detectors.apm.requests import streams
from signalfx.detectors.apm.requests.sudden_change_v2 import sudden_change

def request_rate_mean_std_detector(current_window: duration = duration('10m'),
                                   historical_window: duration = duration('1h'),
                                   fire_num_stddev: float = 3.0,
                                   clear_num_stddev: float = 2.5,
                                   filter_: filter = None):
    # :param current_window label=Current window
    # :param current_window description=Time window to test for anomalous values
    # :param historical_window label=Historical window
    # :param historical_window description=Time window to use for historical normal values
    # :param fire_num_stddev label=Trigger threshold
    # :param fire_num_stddev description=Trigger the alert when the current value is greater than this number of deviations above historical norm
    # :param clear_num_stddev label=Clear growth threshold
    # :param clear_num_stddev description=Clear the alert when the current value is less than this number of deviations above historical norm
    # :param filter_ metric_name=service.request.count
    # :param filter_ dimensions=deployment.environment,service.name
    # :viz valueSuffix=%
    # :return: detect block that triggers when request rate is too many deviations from the norm established in the preceding window

    streams.request_rate_histograms(filter_=filter_, resource_type='service').publish('Request Rate')
    return sudden_change.detector_mean_std(current_window=current_window, historical_window=historical_window,
                                           fire_num_stddev=fire_num_stddev,
                                           clear_num_stddev=clear_num_stddev,
                                           filter_=filter_, resource_type='service',
                                           auto_resolve_after=utils.AUTO_RESOLVE_AFTER)


def blended(guard: float = 30, sensitivity: float = 0.85, filter_: filter = None):
    # Detect when request rate drops, compared to historical request rates
    # :param guard label=Heuristic guardrail (requests per second)
    # :param guard description=Don't alert for services with fewer than this number of requests.
    # :param sensitivity label=Sensitivity multiplier (unitless; usually between 0.5 and 1.0)
    # :param sensitivity description=Lower values push the trigger threshold down, making the detector less sensitive to drops in traffic.
    # :param filter_ label=Additional filter
    # :param filter_ description=Optionally refine the set of observed entities with an additional filter.
    # :param filter_ metric_name=service.request
    # :return: detect block that triggers when traffic drops
    diagnostics = False
    by_ = ['sf_service', 'sf_environment']
    rr = histogram('service.request', filter=filter_, resolution='1s').count(over='1s').rate(by=by_).publish('Request Rate')
    rr_today = rr.percentile(pct=5, over='2h').publish('Last 2h', enable=diagnostics)
    rr_yesterday = rr_today.timeshift('23h').publish('Yesterday', enable=diagnostics)
    rr_weekago = rr_yesterday.timeshift('6d').publish('Week Ago', enable=diagnostics)
    _alert_level = min(rr_today, rr_yesterday, rr_weekago) * sensitivity
    _guard = rr.sum(over='1h')
    alert_level = combine(0 if _guard < guard else _alert_level)
    return detect(
        on=when(rr < threshold(alert_level), lasting='15m', at_least=0.8),
        off=when(rr >= threshold(alert_level), lasting='20m', at_least=0.85),
        auto_resolve_after='1d',
    )
